{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def count11(seq):\n",
    "    count = 0\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 1 and seq[i + 1] == 1:\n",
    "            count = count + 1\n",
    "    return count\n",
    "print(count11([0, 0, 1, 1, 1, 0]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Given data\n",
    "spam_word_counts = {\n",
    "    \"identify\": 1,\n",
    "    \"consultant\": 1,\n",
    "    \"data\": 2,\n",
    "    \"scientist\": 1,\n",
    "    \"machine\": 1,\n",
    "    \"learning\": 1,\n",
    "    \"competitors\": 1,\n",
    "    \"latest\": 2,\n",
    "    \"technology\": 2,\n",
    "    \"freelancer\": 1,\n",
    "    \"cryptocurrency\": 1,\n",
    "    \"dashboard\": 1,\n",
    "    \"drone\": 1,\n",
    "    \"3d\": 1,\n",
    "    \"model\": 1,\n",
    "    \"holiday\": 1,\n",
    "    \"home\": 1,\n",
    "    \"design\": 1,\n",
    "    \"render\": 1,\n",
    "    \"consulting\": 1,\n",
    "    \"services\": 1,\n",
    "    \"implementation\": 1,\n",
    "    \"plan\": 1\n",
    "}\n",
    "\n",
    "ham_word_counts = {\n",
    "    \"business\": 4,\n",
    "    \"ai\": 3,\n",
    "    \"transform\": 1,\n",
    "    \"journey\": 1,\n",
    "    \"maze\": 1,\n",
    "    \"tech\": 1,\n",
    "    \"jargon\": 1,\n",
    "    \"areas\": 1,\n",
    "    \"profits\": 1,\n",
    "    \"revenue\": 1,\n",
    "    \"growth\": 1,\n",
    "    \"products\": 1,\n",
    "    \"customer\": 1,\n",
    "    \"experience\": 1,\n",
    "    \"operational\": 1,\n",
    "    \"workflow\": 1,\n",
    "    \"collecting\": 1,\n",
    "    \"analyzing\": 1,\n",
    "    \"quality\": 1,\n",
    "    \"staying\": 1,\n",
    "    \"abreast\": 1,\n",
    "    \"advances\": 1,\n",
    "    \"demanding\": 1,\n",
    "    \"tailored\": 1,\n",
    "    \"solutions\": 1,\n",
    "    \"revolutionize\": 1,\n",
    "    \"unique\": 1,\n",
    "    \"needs\": 1,\n",
    "    \"learn\": 1,\n",
    "    \"possibilities\": 1,\n",
    "    \"delve\": 1,\n",
    "    \"deeper\": 1,\n",
    "    \"elevate\": 1,\n",
    "    \"insights\": 1,\n",
    "    \"cost\": 3,\n",
    "    \"days\": 3,\n",
    "    \"project\": 1,\n",
    "    \"naive\": 1,\n",
    "    \"bayes\": 1,\n",
    "    \"algorithm\": 1,\n",
    "    \"classify\": 1,\n",
    "    \"info\": 1,\n",
    "    \"provided\": 1,\n",
    "    \"spam\": 1,\n",
    "    \"ham\": 1\n",
    "}\n",
    "\n",
    "# Convert word counts into feature vectors\n",
    "X = []\n",
    "y = []\n",
    "for word, count in spam_word_counts.items():\n",
    "    X.append([count])\n",
    "    y.append(1)  # 1 represents spam\n",
    "\n",
    "for word, count in ham_word_counts.items():\n",
    "    X.append([count])\n",
    "    y.append(0)  # 0 represents ham\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Probability of the message 'million' being spam: 0.7155007256894049\n",
      "2. Probability of the message 'million dollars adclick conferences' being spam: 0.7155007256894049\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "spam_word_counts = {\n",
    "    \"million\": 156,\n",
    "    \"dollars\": 29,\n",
    "    \"adclick\": 51,\n",
    "    \"conferences\": 0\n",
    "}\n",
    "\n",
    "ham_word_counts = {\n",
    "    \"million\": 98,\n",
    "    \"dollars\": 119,\n",
    "    \"adclick\": 0,\n",
    "    \"conferences\": 12\n",
    "}\n",
    "\n",
    "total_spam = 95791\n",
    "total_ham = 306438\n",
    "\n",
    "# Calculate the probability of a message being spam\n",
    "def calculate_spam_probability(message):\n",
    "    words = message.split()\n",
    "    posterior_spam = 1  # Prior odds\n",
    "    posterior_ham = 1\n",
    "\n",
    "    # Update the odds using likelihood ratios for each word\n",
    "    for word in words:\n",
    "        spam_count = spam_word_counts.get(word, 0)  # Get count of word in spam, default to 0\n",
    "        ham_count = ham_word_counts.get(word, 0)    # Get count of word in ham, default to 0\n",
    "        \n",
    "        if spam_count + ham_count > 0:\n",
    "            likelihood_ratio = (spam_count + 1) / (ham_count + 1)  # Laplace smoothing\n",
    "            posterior_spam *= likelihood_ratio\n",
    "            posterior_ham *= (1 / likelihood_ratio)\n",
    "\n",
    "    # Calculate the probability of spam given the message\n",
    "    probability_spam_given_message = posterior_spam / (posterior_spam + posterior_ham)\n",
    "\n",
    "    return probability_spam_given_message\n",
    "\n",
    "# Test message: \"million\"\n",
    "message_1 = \"million\"\n",
    "probability_1_spam = calculate_spam_probability(message_1)\n",
    "\n",
    "# Test message: \"million dollars adclick conferences\"\n",
    "message_2 = \"million dollars adclick conferences\"\n",
    "probability_2_spam = calculate_spam_probability(message_2)\n",
    "\n",
    "# Print results\n",
    "print(\"1. Probability of the message 'million' being spam:\", probability_1_spam)\n",
    "print(\"2. Probability of the message 'million dollars adclick conferences' being spam:\", probability_2_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Posterior odds for spam given message 'million': 0.15579005781946767\n",
      "2. Posterior odds for spam given message 'million dollars adclick conferences': 1.7580475274766318e-05\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "spam_word_counts = {\n",
    "    \"million\": 156,\n",
    "    \"dollars\": 29,\n",
    "    \"adclick\": 51,\n",
    "    \"conferences\": 0\n",
    "}\n",
    "\n",
    "ham_word_counts = {\n",
    "    \"million\": 98,\n",
    "    \"dollars\": 119,\n",
    "    \"adclick\": 0,\n",
    "    \"conferences\": 12\n",
    "}\n",
    "\n",
    "total_spam = 95791\n",
    "total_ham = 306438\n",
    "vocab_size = len(set(spam_word_counts.keys()) | set(ham_word_counts.keys()))\n",
    "\n",
    "# 1. Calculate the probabilities for each word\n",
    "total_words_spam = sum(spam_word_counts.values())\n",
    "total_words_ham = sum(ham_word_counts.values())\n",
    "\n",
    "# 2. Calculate the prior probabilities\n",
    "prior_spam = total_spam / (total_spam + total_ham)\n",
    "prior_ham = total_ham / (total_spam + total_ham)\n",
    "\n",
    "# 3. Calculate the likelihood for each word with Laplace smoothing\n",
    "likelihood_word_spam = {word: (count + 1) / (total_words_spam + vocab_size) for word, count in spam_word_counts.items()}\n",
    "likelihood_word_ham = {word: (count + 1) / (total_words_ham + vocab_size) for word, count in ham_word_counts.items()}\n",
    "\n",
    "# 4. Calculate the posterior probability for each class\n",
    "def calculate_posterior(message):\n",
    "    words = message.split()\n",
    "    posterior_spam = prior_spam\n",
    "    posterior_ham = prior_ham\n",
    "    for word in words:\n",
    "        posterior_spam *= likelihood_word_spam.get(word, 1 / (total_words_spam + vocab_size))\n",
    "        posterior_ham *= likelihood_word_ham.get(word, 1 / (total_words_ham + vocab_size))\n",
    "    \n",
    "    return posterior_spam, posterior_ham\n",
    "\n",
    "# 5. Test message: \"million\"\n",
    "message_1 = \"million\"\n",
    "posterior_1_spam, posterior_1_ham = calculate_posterior(message_1)\n",
    "\n",
    "# 6. Test message: \"million dollars adclick conferences\"\n",
    "message_2 = \"million dollars adclick conferences\"\n",
    "posterior_2_spam, posterior_2_ham = calculate_posterior(message_2)\n",
    "\n",
    "# Print results\n",
    "print(\"1. Posterior odds for spam given message 'million':\", posterior_1_spam)\n",
    "print(\"2. Posterior odds for spam given message 'million dollars adclick conferences':\", posterior_2_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email classified as: ham\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "spam_word_counts = {\n",
    "    \"identify\": 1,\n",
    "    \"consultant\": 1,\n",
    "    \"data\": 2,\n",
    "    \"scientist\": 1,\n",
    "    \"machine\": 1,\n",
    "    \"learning\": 1,\n",
    "    \"competitors\": 1,\n",
    "    \"latest\": 2,\n",
    "    \"technology\": 2,\n",
    "    \"freelancer\": 1,\n",
    "    \"cryptocurrency\": 1,\n",
    "    \"dashboard\": 1,\n",
    "    \"drone\": 1,\n",
    "    \"3d\": 1,\n",
    "    \"model\": 1,\n",
    "    \"holiday\": 1,\n",
    "    \"home\": 1,\n",
    "    \"design\": 1,\n",
    "    \"render\": 1,\n",
    "    \"consulting\": 1,\n",
    "    \"services\": 1,\n",
    "    \"implementation\": 1,\n",
    "    \"plan\": 1\n",
    "}\n",
    "\n",
    "ham_word_counts = {\n",
    "    \"business\": 4,\n",
    "    \"ai\": 3,\n",
    "    \"transform\": 1,\n",
    "    \"journey\": 1,\n",
    "    \"maze\": 1,\n",
    "    \"tech\": 1,\n",
    "    \"jargon\": 1,\n",
    "    \"areas\": 1,\n",
    "    \"profits\": 1,\n",
    "    \"revenue\": 1,\n",
    "    \"growth\": 1,\n",
    "    \"products\": 1,\n",
    "    \"customer\": 1,\n",
    "    \"experience\": 1,\n",
    "    \"operational\": 1,\n",
    "    \"workflow\": 1,\n",
    "    \"collecting\": 1,\n",
    "    \"analyzing\": 1,\n",
    "    \"quality\": 1,\n",
    "    \"staying\": 1,\n",
    "    \"abreast\": 1,\n",
    "    \"advances\": 1,\n",
    "    \"demanding\": 1,\n",
    "    \"tailored\": 1,\n",
    "    \"solutions\": 1,\n",
    "    \"revolutionize\": 1,\n",
    "    \"unique\": 1,\n",
    "    \"needs\": 1,\n",
    "    \"learn\": 1,\n",
    "    \"possibilities\": 1,\n",
    "    \"delve\": 1,\n",
    "    \"deeper\": 1,\n",
    "    \"elevate\": 1,\n",
    "    \"insights\": 1,\n",
    "    \"cost\": 3,\n",
    "    \"days\": 3,\n",
    "    \"project\": 1,\n",
    "    \"naive\": 1,\n",
    "    \"bayes\": 1,\n",
    "    \"algorithm\": 1,\n",
    "    \"classify\": 1,\n",
    "    \"info\": 1,\n",
    "    \"provided\": 1,\n",
    "    \"spam\": 1,\n",
    "    \"ham\": 1\n",
    "}\n",
    "\n",
    "total_spam = sum(spam_word_counts.values())\n",
    "total_ham = sum(ham_word_counts.values())\n",
    "vocab_size = len(set(spam_word_counts.keys()) | set(ham_word_counts.keys()))\n",
    "\n",
    "# Prior probabilities\n",
    "prior_spam = total_spam / (total_spam + total_ham)\n",
    "prior_ham = total_ham / (total_spam + total_ham)\n",
    "\n",
    "# Calculate the likelihood for each word with Laplace smoothing\n",
    "def calculate_likelihood(word_counts, total_count):\n",
    "    return {word: (count + 1) / (total_count + vocab_size) for word, count in word_counts.items()}\n",
    "\n",
    "likelihood_word_spam = calculate_likelihood(spam_word_counts, total_spam)\n",
    "likelihood_word_ham = calculate_likelihood(ham_word_counts, total_ham)\n",
    "\n",
    "# Classify the email\n",
    "def classify_email(email):\n",
    "    words = email.lower().split()\n",
    "    posterior_spam = prior_spam\n",
    "    posterior_ham = prior_ham\n",
    "    for word in words:\n",
    "        posterior_spam *= likelihood_word_spam.get(word, 1 / (total_spam + vocab_size))\n",
    "        posterior_ham *= likelihood_word_ham.get(word, 1 / (total_ham + vocab_size))\n",
    "    \n",
    "    if posterior_spam > posterior_ham:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\"\n",
    "\n",
    "# Test the classification\n",
    "email = \"\"\"\n",
    "Transform 2024\n",
    "\n",
    "with AI:\n",
    "\n",
    "3 Step Guide\n",
    "\n",
    "Hi Joseph\n",
    "\n",
    "Embarking on an AI journey for your business might feel like navigating a maze of tech jargon.\n",
    "\n",
    "Feeling a bit lost? Fear not!\n",
    "\n",
    "We've crafted a three-step guide for your business's AI transformation. Let's turn confusion into clarity and make your AI adventure a stroll in the digital park.\n",
    "\n",
    "How to transform your business in 3 steps:\n",
    "\n",
    "1. Identify what the new world of AI can do for your business\n",
    "\n",
    "Identify key areas in your business, such as profits, revenue, growth, products, services, customer experience, and operational workflow. Evaluate where AI can enhance efficiency and performance. For the best results, engage an AI Consultant for personalized insights and a recommended implementation plan.\n",
    "\n",
    "2. Unlock the potential of your data with AI\n",
    "\n",
    "Collecting and analyzing data is a crucial step in AI implementation. The quality of the data used to train AI models directly affects the accuracy and effectiveness of the models. This can be a complicated process, better suited to a skilled Data Scientist and Machine Learning Engineer.\n",
    "\n",
    "3. Get an edge over your competitors with the latest technology\n",
    "\n",
    "The field of artificial intelligence is in a constant state of evolution. Staying abreast of the latest advances can be demanding, which is why consulting with experts, readily available on Freelancer, ensures that you harness cutting-edge AI solutions tailored to your business needs.\n",
    "\n",
    "Explore the possibilities and delve deeper into how AI can elevate your business. From personalized insights to tailored solutions, we're here to revolutionize your business together, unlocking the full potential of AI innovation for your unique needs.\n",
    "\n",
    "Learn more about AI What our AI-powered freelancers can do for you: Cryptocurrency Dashboard This cryptocurrency dashboard cost $540 USD and took 7 days\n",
    "\n",
    "Conceptual Drone 3D Model This conceptual drone 3D model cost $330 USD and took 5 days\n",
    "\n",
    "Holiday Home Design and Render This holiday home design and render cost $180 USD and took 6 days\n",
    "\n",
    "Post a project\n",
    "\"\"\"\n",
    "\n",
    "classification = classify_email(email)\n",
    "print(\"Email classified as:\", classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Extract the email text\n",
    "email_text = \"\"\"\n",
    "Transform 2024\n",
    "\n",
    "with AI:\n",
    "\n",
    "3 Step Guide\n",
    "\n",
    "Hi Joseph\n",
    "\n",
    "Embarking on an AI journey for your business might feel like navigating a maze of tech jargon.\n",
    "\n",
    "Feeling a bit lost? Fear not!\n",
    "\n",
    "We've crafted a three-step guide for your business's AI transformation. Let's turn confusion into clarity and make your AI adventure a stroll in the digital park.\n",
    "\n",
    "How to transform your business in 3 steps:\n",
    "\n",
    "1. Identify what the new world of AI can do for your business\n",
    "\n",
    "Identify key areas in your business, such as profits, revenue, growth, products, services, customer experience, and operational workflow. Evaluate where AI can enhance efficiency and performance. For the best results, engage an AI Consultant for personalized insights and a recommended implementation plan.\n",
    "\n",
    "2. Unlock the potential of your data with AI\n",
    "\n",
    "Collecting and analyzing data is a crucial step in AI implementation. The quality of the data used to train AI models directly affects the accuracy and effectiveness of the models. This can be a complicated process, better suited to a skilled Data Scientist and Machine Learning Engineer.\n",
    "\n",
    "3. Get an edge over your competitors with the latest technology\n",
    "\n",
    "The field of artificial intelligence is in a constant state of evolution. Staying abreast of the latest advances can be demanding, which is why consulting with experts, readily available on Freelancer, ensures that you harness cutting-edge AI solutions tailored to your business needs.\n",
    "\n",
    "Explore the possibilities and delve deeper into how AI can elevate your business. From personalized insights to tailored solutions, we're here to revolutionize your business together, unlocking the full potential of AI innovation for your unique needs.\n",
    "\n",
    "Learn more about AI What our AI-powered freelancers can do for you: Cryptocurrency Dashboard This cryptocurrency dashboard cost $540 USD and took 7 days\n",
    "\n",
    "Conceptual Drone 3D Model This conceptual drone 3D model cost $330 USD and took 5 days\n",
    "\n",
    "Holiday Home Design and Render This holiday home design and render cost $180 USD and took 6 days\n",
    "\n",
    "Post a project\n",
    "\"\"\"\n",
    "\n",
    "# Labels: 1 for spam, 0 for ham\n",
    "spam_labels = [1, 1, 1]\n",
    "ham_labels = [0, 0, 0]\n",
    "\n",
    "# Duplicate emails and labels\n",
    "emails = [email_text] * len(spam_labels + ham_labels)\n",
    "labels = spam_labels + ham_labels\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(emails, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the emails using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predictions on the testing set\n",
    "y_pred = clf.predict(X_test_counts)\n",
    "\n",
    "print(\"Predictions:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the message being spam: 0.9848752510708322\n"
     ]
    }
   ],
   "source": [
    "# Given likelihood ratios\n",
    "likelihood_ratios = {\n",
    "    \"million\": 5.1,\n",
    "    \"dollars\": 0.8,\n",
    "    \"adclick\": 53.2,\n",
    "    \"conferences\": 0.3\n",
    "}\n",
    "\n",
    "# Calculate the probability of a message being spam\n",
    "def calculate_spam_probability(message):\n",
    "    words = message.split()\n",
    "    posterior_odds = 1  # Prior odds\n",
    "\n",
    "    # Update the odds using likelihood ratios for each word\n",
    "    for word in words:\n",
    "        likelihood_ratio = likelihood_ratios.get(word, 1)  # Default to 1 if word not found\n",
    "        posterior_odds *= likelihood_ratio\n",
    "\n",
    "    # Calculate the probability of spam given the message\n",
    "    probability_spam_given_message = posterior_odds / (1 + posterior_odds)\n",
    "\n",
    "    return probability_spam_given_message\n",
    "\n",
    "# Test message: \"million dollars adclick conferences\"\n",
    "message_2_spam_probability = calculate_spam_probability(message_2)\n",
    "print(\"Probability of the message being spam:\", message_2_spam_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yugMU9MjJtBl"
   },
   "source": [
    "# Exemplar: Build a Naive Bayes model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzWqJunmJotv"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this activity, you will build your own Naive Bayes model. Naive Bayes models can be valuable to use any time you are doing work with predictions because they give you a way to account for new information. In today's world, where data is constantly evolving, modeling with Naive Bayes can help you adapt quickly and make more accurate predictions about what could occur.\n",
    "\n",
    "For this activity, you work for a firm that provides insights for management and coaches in the National Basketball Association (NBA), a professional basketball league in North America. The league is interested in retaining players who can last in the high-pressure environment of professional basketball and help the team be successful over time. In the previous activity, you analyzed a subset of data that contained information about the NBA players and their performance records. You conducted feature engineering to determine which features would most effectively predict a player's career duration. You will now use those insights to build a model that predicts whether a player will have an NBA career lasting five years or more. \n",
    "\n",
    "The data for this activity consists of performance statistics from each player's rookie year. There are 1,341 observations, and each observation in the data represents a different player in the NBA. Your target variable is a Boolean value that indicates whether a given player will last in the league for five years. Since you previously performed feature engineering on this data, it is now ready for modeling.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTVinL1hJqoy"
   },
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDIRpqkZJ4S8"
   },
   "source": [
    "### Import packages\n",
    "\n",
    "Begin with your import statements. Of particular note here are `pandas` and from `sklearn`, `naive_bayes`, `model_selection`, and `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1nDjAJPa4lVZ"
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries and modules.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKylHziGzY3X"
   },
   "source": [
    "### Load the dataset\n",
    "\n",
    "Recall that in the lab about feature engineering, you outputted features for the NBA player dataset along with the target variable ``target_5yrs``. Data was imported as a DataFrame called `extracted_data`. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "error",
     "timestamp": 1659773891997,
     "user": {
      "displayName": "Gracen Hanley",
      "userId": "14517815644308397440"
     },
     "user_tz": 420
    },
    "id": "4ebqpNcm4BDH",
    "outputId": "5d7a78b6-3474-4fff-e6f5-376482e8eba9"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO IMPORT YOUR DATA.\n",
    "# Load extracted_nba_players_data.csv into a DataFrame called extracted_data.\n",
    "\n",
    "extracted_data = pd.read_csv(r'C:\\Users\\USER\\Downloads\\extracted_nba_players_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bg_6M3IRgMU"
   },
   "source": [
    "### Display the data\n",
    "\n",
    "Review the first 10 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JWu8u19C2sn1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg</th>\n",
       "      <th>3p</th>\n",
       "      <th>ft</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>target_5yrs</th>\n",
       "      <th>total_points</th>\n",
       "      <th>efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>266.4</td>\n",
       "      <td>0.270073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.267658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.339869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.491379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>277.5</td>\n",
       "      <td>0.324561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>409.2</td>\n",
       "      <td>0.605505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>273.6</td>\n",
       "      <td>0.553398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>67.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>155.4</td>\n",
       "      <td>0.435294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.5</td>\n",
       "      <td>33.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>77.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>47.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.196970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32.3</td>\n",
       "      <td>30.1</td>\n",
       "      <td>86.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.366013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>105.6</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>51.4</td>\n",
       "      <td>14.3</td>\n",
       "      <td>68.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.426230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>102.9</td>\n",
       "      <td>0.396226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>34.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>73.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.404762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>49.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1574.4</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49.0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1574.4</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fg    3p    ft   reb  ast  stl  blk  tov  target_5yrs  total_points  \\\n",
       "0   34.7  25.0  69.9   4.1  1.9  0.4  0.4  1.3            0         266.4   \n",
       "1   29.6  23.5  76.5   2.4  3.7  1.1  0.5  1.6            0         252.0   \n",
       "2   42.2  24.4  67.0   2.2  1.0  0.5  0.3  1.0            0         384.8   \n",
       "3   42.6  22.6  68.9   1.9  0.8  0.6  0.1  1.0            1         330.6   \n",
       "4   52.4   0.0  67.4   2.5  0.3  0.3  0.4  0.8            1         216.0   \n",
       "5   42.3  32.5  73.2   0.8  1.8  0.4  0.0  0.7            0         277.5   \n",
       "6   43.5  50.0  81.1   2.0  0.6  0.2  0.1  0.7            1         409.2   \n",
       "7   41.5  30.0  87.5   1.7  0.2  0.2  0.1  0.7            1         273.6   \n",
       "8   39.2  23.3  71.4   0.8  2.3  0.3  0.0  1.1            0         156.0   \n",
       "9   38.3  21.4  67.8   1.1  0.3  0.2  0.0  0.7            0         155.4   \n",
       "10  36.5  33.3  81.8   0.9  0.7  0.1  0.1  0.3            0          80.5   \n",
       "11  39.8  13.6  77.6   1.2  0.4  0.3  0.1  0.6            1         144.0   \n",
       "12  47.2   0.0  28.6   2.0  0.2  0.2  0.6  0.3            1          35.1   \n",
       "13  32.3  30.1  86.1   2.0  0.5  0.5  0.3  0.5            0         252.0   \n",
       "14  53.7   0.0  50.0   1.4  0.2  0.2  0.4  0.6            1         105.6   \n",
       "15  51.4  14.3  68.4   0.4  1.4  0.3  0.0  0.8            1         104.0   \n",
       "16  37.6   0.0  64.2   1.2  0.2  0.3  0.2  0.5            0         102.9   \n",
       "17  34.8  21.4  73.1   0.3  1.0  0.3  0.0  0.4            0          69.7   \n",
       "18  49.0  22.7  82.9  11.0  3.6  1.0  0.6  1.9            0        1574.4   \n",
       "19  49.0  22.7  82.9  11.0  3.6  1.0  0.6  1.9            1        1574.4   \n",
       "\n",
       "    efficiency  \n",
       "0     0.270073  \n",
       "1     0.267658  \n",
       "2     0.339869  \n",
       "3     0.491379  \n",
       "4     0.391304  \n",
       "5     0.324561  \n",
       "6     0.605505  \n",
       "7     0.553398  \n",
       "8     0.242424  \n",
       "9     0.435294  \n",
       "10    0.333333  \n",
       "11    0.537313  \n",
       "12    0.196970  \n",
       "13    0.366013  \n",
       "14    0.375000  \n",
       "15    0.426230  \n",
       "16    0.396226  \n",
       "17    0.404762  \n",
       "18    0.516129  \n",
       "19    0.516129  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of data.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "extracted_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zz8claq0Swi"
   },
   "source": [
    "## Step 2: Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kgPx_MP0cuc"
   },
   "source": [
    "### Isolate your target and predictor variables\n",
    "Separately define the target variable (`target_5yrs`) and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xO46EzS8oBIG"
   },
   "outputs": [],
   "source": [
    "# Define the y (target) variable.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "y = extracted_data['target_5yrs']\n",
    "\n",
    "# Define the X (predictor) variables.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "X = extracted_data.drop('target_5yrs', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzQNmlZ75e_Y"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data into X and y](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWXkObsg5gzd"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "In `pandas`, subset your DataFrame by using square brackets `[]` to specify which column(s) to select.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU9z6ufC5n58"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Quickly subset a DataFrame to exclude a particular column by using the `drop()` function and specifying the column to drop.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj8-Pb0N-rjW"
   },
   "source": [
    "### Display the first 10 rows of your target data\n",
    "\n",
    "Display the first 10 rows of your target and predictor variables. This will help you get a sense of how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pivKfaxQ5uHZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "6    1\n",
       "7    1\n",
       "8    0\n",
       "9    0\n",
       "Name: target_5yrs, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of your target data.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDls2RifZhu2"
   },
   "source": [
    "**Question:** What do you observe about the your target variable?\n",
    "\n",
    "Given that the target variable contains both 1 and 0 indicates that it is binary and requires a model suitable for binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2kDZK5qe-4B0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg</th>\n",
       "      <th>3p</th>\n",
       "      <th>ft</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>total_points</th>\n",
       "      <th>efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>69.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>266.4</td>\n",
       "      <td>0.270073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.267658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42.2</td>\n",
       "      <td>24.4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.339869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>68.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>330.6</td>\n",
       "      <td>0.491379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>277.5</td>\n",
       "      <td>0.324561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>409.2</td>\n",
       "      <td>0.605505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>273.6</td>\n",
       "      <td>0.553398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>71.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>67.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>155.4</td>\n",
       "      <td>0.435294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fg    3p    ft  reb  ast  stl  blk  tov  total_points  efficiency\n",
       "0  34.7  25.0  69.9  4.1  1.9  0.4  0.4  1.3         266.4    0.270073\n",
       "1  29.6  23.5  76.5  2.4  3.7  1.1  0.5  1.6         252.0    0.267658\n",
       "2  42.2  24.4  67.0  2.2  1.0  0.5  0.3  1.0         384.8    0.339869\n",
       "3  42.6  22.6  68.9  1.9  0.8  0.6  0.1  1.0         330.6    0.491379\n",
       "4  52.4   0.0  67.4  2.5  0.3  0.3  0.4  0.8         216.0    0.391304\n",
       "5  42.3  32.5  73.2  0.8  1.8  0.4  0.0  0.7         277.5    0.324561\n",
       "6  43.5  50.0  81.1  2.0  0.6  0.2  0.1  0.7         409.2    0.605505\n",
       "7  41.5  30.0  87.5  1.7  0.2  0.2  0.1  0.7         273.6    0.553398\n",
       "8  39.2  23.3  71.4  0.8  2.3  0.3  0.0  1.1         156.0    0.242424\n",
       "9  38.3  21.4  67.8  1.1  0.3  0.2  0.0  0.7         155.4    0.435294"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of your predictor variables.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Albdy39HZwQT"
   },
   "source": [
    "**Question:** What do you observe about the your predictor variables?\n",
    "\n",
    "The data indicates that all of the predictor variables are continuous numerical values, so it is important that the model selected is suitable for continuous features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ-wo4UOoBII"
   },
   "source": [
    "### Perform a split operation on your data\n",
    "\n",
    "Divide your data into a training set (75% of data) and test set (25% of data). This is an important step in the process, as it allows you to reserve a part of the data that the model has not observed. This tests how well the model generalizes—or performs—on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pO2AdPR7oBIJ"
   },
   "outputs": [],
   "source": [
    "# Perform the split operation on your data.\n",
    "# Assign the outputs as follows: X_train, X_test, y_train, y_test.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgY9icEY2mKn"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data between a training and test set](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUmzKZUU2mKp"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call the function in the `model_selection` module of `sklearn` on the features and target variable, in order to perform the splitting.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORy1MNR62mKq"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call the `model_selection.train_test_split()` function, passing in both `features` and `target`, while configuring the appropriate `test_size`.\n",
    "\n",
    "Assign the output of this split as `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjasizab0tSL"
   },
   "source": [
    "### Print the shape of each output \n",
    "\n",
    "Print the shape of each output from your train-test split. This will verify that the split operated as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xtxpSjCm4jCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1005, 10)\n",
      "(335, 10)\n",
      "(1005,)\n",
      "(335,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape (rows, columns) of the output from the train-test split.\n",
    "\n",
    "# Print the shape of X_train.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_test.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "# Print the shape of y_train.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "# Print the shape of y_test.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx8DO1Rw2ZBZ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Call the attribute that DataFrames in `pandas` have to get the number of rows and number of columns as a tuple.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9pDSxlG2di1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call the `shape` attribute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCIsGmSESpu5"
   },
   "source": [
    "**Question:** How many rows are in each of the outputs?\n",
    "\n",
    "Each training DataFrame contains 1,005 rows, while each test DataFrame contains 335 rows. Additionally, there are 10 columns in each X DataFrame, with only one column in each y DataFrame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZndsnPq1UyL"
   },
   "source": [
    "**Question:** What was the effect of the train-test split?\n",
    "\n",
    "The effect of the train-test split showed an approximately 75% training and 25% test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY0rAjlZAheh"
   },
   "source": [
    "## Step 3: Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS06KhTSoBIM"
   },
   "source": [
    "**Question:** Which Naive Bayes algorithm should you use?\n",
    "\n",
    "Using the assumption that your features are normally distributed and continuous, the Gaussian Naive Bayes algorithm is most appropriate for your data. While your data may not perfectly adhere to these assumptions, this model will still yield the most usable and accurate results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOBvfCNeoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about different implementations of the Naive Bayes](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/supplement/1zfDy/naive-bayes-classifiers) to determine which is appropriate in this situation.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzT16WHjoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Note that you are performing binary classification.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IILInxLYoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "You can identify the appropriate algorithm to use because you are performing a binary classification and assuming that the features of your model follow a normal distribution.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5EFtZfXoBIN"
   },
   "source": [
    "### Fit your model to your training data and predict on your test data\n",
    "\n",
    "By creating your model, you will be drawing on your feature engineering work by training the classifier on the `X_train` DataFrame. You will use this to predict `target_5yrs` from `y_train`.\n",
    "\n",
    "Start by defining `nb` to be the relevant algorithm from `sklearn`.`naive_bayes`. Then fit your model to your training data. Use this fitted model to create predictions for your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gUEgzQW_6oMV"
   },
   "outputs": [],
   "source": [
    "# Assign `nb` to be the appropriate implementation of Naive Bayes.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "nb = naive_bayes.GaussianNB()\n",
    "\n",
    "# Fit the model on your training data.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Apply your model to predict on your test data. Call this \"y_pred\".\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2vRT5XeoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about constructing a Naive Bayes](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo1E7RjtoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The appropriate implementation in this case is `naive_bayes`.`GaussianNB()`. Fit this model to your training data and predict on your test data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azSq51xXoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `fit()`and pass your training feature set and target variable. Then call `predict()` on your test feature set.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgV_6xAQAvgg"
   },
   "source": [
    "## Step 4: Results and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPswDdr1oBIO"
   },
   "source": [
    "### Leverage metrics to evaluate your model's performance\n",
    "\n",
    "To evaluate the data yielded from your model, you can leverage a series of metrics and evaluation techniques from scikit-learn by examining the actual observed values in the test set relative to your model's prediction. Specifically, print the accuracy score, precision score, recall score, and f1 score associated with your test data and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "INf2Rd_MoBIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.6895522388059702\n",
      "precision score:\n",
      "0.8405797101449275\n",
      "recall score:\n",
      "0.5858585858585859\n",
      "f1 score:\n",
      "0.6904761904761905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print your accuracy score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print('accuracy score:'), print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print your precision score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print('precision score:'), print(metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Print your recall score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print('recall score:'), print(metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Print your f1 score.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "print('f1 score:'), print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEgb0a2YoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about model evaluation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/EITmV/key-evaluation-metrics-for-classification-models) for detail on these metrics.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT143KsSoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The `metrics` module in `sklearn` has a function for computing each of these metrics.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BECv4a2toBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `accuracy_score()`, `precision_score()`, `recall_score()`, and `f1_score()`, passing `y_test`, and `y_pred` into each function.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDx7rrdNoBIP"
   },
   "source": [
    "**Question:** What is the accuracy score for your model, and what does this tell you about the success of the model's performance?\n",
    "\n",
    "The accuracy score for this model is 0.6896, or 69.0% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QirKWngCah9v"
   },
   "source": [
    "**Question:** Can you evaluate the success of your model by using the accuracy score exclusively?\n",
    "\n",
    "In classification problems, accuracy is useful to know but may not be the best metric by which to evaluate this model. While accuracy is often the most intuitive metric, it is a poor evaluation metric in some cases. In particular, if you have imbalanced classes, a model could appear accurate but be poor at balancing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evpAa_4noBIP"
   },
   "source": [
    "**Question:** What are the precision and recall scores for your model, and what do they mean? Is one of these scores more accurate than the other?\n",
    "\n",
    "Precision and recall scores are both useful to evaluate the correct predictive capability of a model because they balance the false positives and false negatives inherent in prediction.\n",
    "\n",
    "The model shows a precision score of 0.8406, suggesting the model is quite good at predicting true positives—meaning the player will play longer than five years—while balancing false positives. The recall score of 0.5859 shows worse performance in predicting true negatives—where the player will not play for five years or more—while balancing false negatives.These two metrics combined can give a better assessment of model performance than accuracy does alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ghkTwSUoBIP"
   },
   "source": [
    "**Question:** What is the F1 score of your model, and what does this score mean?\n",
    "\n",
    "The F1 score balances the precision and recall performance to give a combined assessment of how well this model delivers predictions. In this case, the F1 score is 0.6905, which suggests reasonable predictive power in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzDfI3RoBIQ"
   },
   "source": [
    "### Gain clarity with the confusion matrix\n",
    "\n",
    "Recall that a confusion matrix is a graphic that shows your model's true and false positives and negatives. It helps to create a visual representation of the components feeding into the metrics.\n",
    "\n",
    "Create a confusion matrix based on your predicted values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ntoJ-YG7oBIQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x19ae78e2750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct and display your confusion matrix.\n",
    "\n",
    "# Construct the confusion matrix for your predicted and test values.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create the display for your confusion matrix.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=nb.classes_)\n",
    "\n",
    "# Plot the visual in-line.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2lqmzQ-oBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `metrics` module has functions to create a confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_x2zTDoBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call `confusion_matrix`, passing in `y_test` and `y_pred`. Then, utilize `ConfusionMatrixDisplay()` to display your confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLkF5znkNk7m"
   },
   "source": [
    "**Question:** What do you notice when observing your confusion matrix, and does this correlate to any of your other calculations?\n",
    "\n",
    "- The top left to bottom right diagonal in the confusion matrix represents the correct predictions, and the ratio of these squares showcases the accuracy.\n",
    "\n",
    "- The concentration of true positives stands out relative to false positives. This ratio is why the precision score is so high (0.8406).\n",
    "\n",
    "- True negatives and false negatives are closer in number, which explains the worse recall score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xur2FC5xAzp0"
   },
   "source": [
    "## Considerations\n",
    "\n",
    "**What are some key takeaways that you learned from this lab?**\n",
    "- The evaluation of the model is important to inform if the model has delivered accurate predictions.\n",
    "- Splitting the data was important for ensuring that there was new data for the model to test its predictive performance.\n",
    "- Each metric provided an evaluation from a different standpoint, and accuracy alone was not a strong way to evaluate the model. \n",
    "- Effective assessments balance the true/false positives versus true/false negatives through the confusion matrix and F1 score.\n",
    "\n",
    "**How would you present your results to your team?**\n",
    "- Showcase the data used to create the prediction and the performance of the model overall.\n",
    "- Review the sample output of the features and the confusion matrix to indicate the model's performance.\n",
    "- Highlight the metric values, emphasizing the F1 score.\n",
    "\n",
    "**How would you summarize your findings to stakeholders?**\n",
    "- The model created provides some value in predicting an NBA player's chances of playing for five years or more.\n",
    "- Notably, the model performed better at predicting true positives than it did at predicting true negatives. In other words, it more accurately identified those players who will likely play for more than five years than it did those who likely will not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
