{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ad77a50",
   "metadata": {},
   "source": [
    "Here's a demonstration. This example uses a decision tree regressor. \n",
    "\n",
    "Imagine that the target is a continuous variable. \n",
    "\n",
    "Let's start with a set of features X and a target variable Y. \n",
    "\n",
    "We'll train the first base learner decision tree on this data and call it learner1. \n",
    "\n",
    "learner1 makes its predictions, which we'll call Y^_1. \n",
    "\n",
    "The residual errors of learner1's prediction are found by subtracting the predicted values from the actual values. \n",
    "\n",
    "Call the set of residual errors, error_1. \n",
    "\n",
    "Now train a new base learner using the same X data but instead of the original Y data, use error_1 as the target. \n",
    "\n",
    "That's because this learner is predicting the error made by learner1. \n",
    "\n",
    "Call this new base learner, learner2. \n",
    "\n",
    "Learner2's predictions are assigned to error^_1. \n",
    "\n",
    "Then compare learner2's predictions to the actual values and assign the difference to error_2. \n",
    "\n",
    "In this case, the actual values are the errors made by learner1. \n",
    "\n",
    "This process will continue for as many base learners as we specify. \n",
    "\n",
    "For now, repeat it just once more. \n",
    "\n",
    "Stopping here results in an ensemble that contains three base learners. \n",
    "\n",
    "To get the final prediction for any new X, add together the predictions of all three learners.  \n",
    "\n",
    "Ensembles that use gradient boosting are called gradient boosting machines or GBMs. \n",
    "\n",
    "GBMs are among the most widely used modeling techniques today because of their many advantages. \n",
    "\n",
    "One of these is high accuracy. As we mentioned earlier, many machine-learning competition winners succeeded largely because of the accuracy of their boosting models. \n",
    "\n",
    "Another advantage is that GBMs are scalable. \n",
    "\n",
    "Even though they can't be trained in parallel, like random forests, because they're base learners are developed sequentially they still scale well to large datasets. \n",
    "\n",
    "GBMs also work well with missing data. \n",
    "\n",
    "The fact that a value is missing is viewed as valuable information. \n",
    "\n",
    "So GBMs treat missing values just like any other value when determining how to split a feature. \n",
    "\n",
    "This makes gradient boosting relatively easy to use with messy data. \n",
    "\n",
    "Also because they are tree-based, GBMs don't require the data to be scaled and they can handle outliers easily. \n",
    "\n",
    "Gradient boosting also has its drawbacks. One is that GBMs have a lot of hyperparameters, and tuning them can be a time-consuming process. \n",
    "\n",
    "Another drawback is that they can be difficult to interpret. \n",
    "\n",
    "GBMs can provide feature importance but unlike linear models, they do not have coefficients or directionality. \n",
    "\n",
    "They only show how important each feature is relative to the other features. Because of this, they're often called black-box models. \n",
    "\n",
    "This is a model whose predictions cannot be precisely explained. In some industries such as medicine and banking, it's essential that your model's predictions be explainable. \n",
    "\n",
    "Therefore, GBMs are not well suited for some applications. \n",
    "\n",
    "GBMs can also have difficulty with extrapolation. \n",
    "\n",
    "Extrapolation is a model's ability to predict new values that fall outside of the range of values in the training data. \n",
    "\n",
    "For instance, if one loaf of bread costs one dollar, two loaves of bread cost two dollars, and three loaves cost three dollars. A linear regression model would have no trouble predicting that 10 loaves cost $10, but a GBM wouldn't be able to unless it saw the cost of 10 loaves in the training data.\n",
    "\n",
    "Finally, GBMs are prone to overfitting if not trained carefully. \n",
    "\n",
    "Usually this is caused by tuning too many hyperparameters, which can result in the trees growing to fit the training data, but not generalizing well to unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ab5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa2681b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>CholesterolLevel</th>\n",
       "      <th>FastingBloodSugar</th>\n",
       "      <th>RestingElectrocardiographicResult</th>\n",
       "      <th>MaxHeartRate</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>STDepression</th>\n",
       "      <th>STSegmentSlope</th>\n",
       "      <th>NumMajorVessels</th>\n",
       "      <th>ThalliumStressRest</th>\n",
       "      <th>HeartDiseasePresent</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  CholesterolLevel  FastingBloodSugar  \\\n",
       "0   63    1              1        145               233                  1   \n",
       "1   67    1              4        160               286                  0   \n",
       "2   67    1              4        120               229                  0   \n",
       "3   37    1              3        130               250                  0   \n",
       "4   41    0              2        130               204                  0   \n",
       "5   56    1              2        120               236                  0   \n",
       "6   62    0              4        140               268                  0   \n",
       "7   57    0              4        120               354                  0   \n",
       "8   63    1              4        130               254                  0   \n",
       "9   53    1              4        140               203                  1   \n",
       "\n",
       "   RestingElectrocardiographicResult  MaxHeartRate  ExerciseAngina  \\\n",
       "0                                  2           150               0   \n",
       "1                                  2           108               1   \n",
       "2                                  2           129               1   \n",
       "3                                  0           187               0   \n",
       "4                                  2           172               0   \n",
       "5                                  0           178               0   \n",
       "6                                  2           160               0   \n",
       "7                                  0           163               1   \n",
       "8                                  2           147               0   \n",
       "9                                  2           155               1   \n",
       "\n",
       "   STDepression  STSegmentSlope  NumMajorVessels  ThalliumStressRest  \\\n",
       "0           2.3               3                0                   6   \n",
       "1           1.5               2                3                   3   \n",
       "2           2.6               2                2                   7   \n",
       "3           3.5               3                0                   3   \n",
       "4           1.4               1                0                   3   \n",
       "5           0.8               1                0                   3   \n",
       "6           3.6               3                2                   3   \n",
       "7           0.6               1                0                   3   \n",
       "8           1.4               2                1                   7   \n",
       "9           3.1               3                0                   7   \n",
       "\n",
       "   HeartDiseasePresent  Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  \\\n",
       "0                    0          NaN          NaN          NaN          NaN   \n",
       "1                    1          NaN          NaN          NaN          NaN   \n",
       "2                    1          NaN          NaN          NaN          NaN   \n",
       "3                    0          NaN          NaN          NaN          NaN   \n",
       "4                    0          NaN          NaN          NaN          NaN   \n",
       "5                    0          NaN          NaN          NaN          NaN   \n",
       "6                    1          NaN          NaN          NaN          NaN   \n",
       "7                    0          NaN          NaN          NaN          NaN   \n",
       "8                    1          NaN          NaN          NaN          NaN   \n",
       "9                    1          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 18  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_tidy.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7ae7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 14','Unnamed: 15','Unnamed: 16','Unnamed: 17','Unnamed: 18'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b74ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3321.00466126722\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'data' is your dataframe containing the dataset\n",
    "\n",
    "# Splitting the data into predictors (X) and target variable (y)\n",
    "X = df.drop('CholesterolLevel', axis=1)\n",
    "y = df['CholesterolLevel']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Gradient Boosting Regressor\n",
    "gb_regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Training the Gradient Boosting Regressor\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the model using mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067ac0f",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE): MSE is a commonly used metric for evaluating regression models. It measures the average squared difference between the actual values (y_true) and the predicted values (y_pred). Mathematically, it is calculated as the average of the squared differences between the actual and predicted values:\n",
    "\n",
    "Interpretation: A lower MSE indicates that the model's predictions are closer to the actual values, while a higher MSE indicates larger prediction errors. In this case, an MSE of 3321 means that, on average, the squared difference between the actual and predicted cholesterol levels is 3321 mg/dL². Since MSE is in squared units (mg/dL² in this case), it's not directly interpretable in terms of the original units (mg/dL). However, it gives a measure of the overall accuracy of the model's predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
